\section{Conclusion}
\label{sec:conclusion}
We have discussed neural networks, a biologically inspired computing model that dominates modern machine learning. Neural networks are complex networks of simple units which are arranged in a layered architecture. By propagating an input through its layers, a neural network can make sophisticated predictions, such as which class the input is most likely to belong to.

Feedforward neural networks can be represented as a chain of matrix operations and applications of nonlinear functions. The parameters of the model are chosen during training, where a cost function that measures the performance of the network is minimized. The most common algorithm to achieve this is stochastic gradient descent, which requires the computation of the gradient of the cost function. This is efficiently handled by the back-propagation algorithm.

Deep learning, the branch of machine learning that is concerned with the development of deep neural networks, has enabled an outstanding amount of advances in the field. We expect that, with ever-increasing datasets and computational power, as well as the development of more complex and refined models, neural networks will continue to have a great impact on technology and will power more and more intelligent systems in the future.