\begin{abstract}
Neural networks are biologically inspired computation models that have shaped the field of machine learning over the last decade, enabling breakthroughs in numerous application areas ranging from image processing to natural language understanding. In this paper, we review the fundamental principles behind neural networks, providing the reader with the necessary mathematical knowledge to be able to use them in practice. We examine the development of neural networks from simpler models, their architecture and related design decisions, and their mathematical specification. We then explore the most common training algorithm employed in neural networks. Finally, we briefly discuss more advanced network architectures and the continued impact we believe neural networks will have on machine learning.
\end{abstract}
