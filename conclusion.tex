\section{Conclusion}
\label{sec:conclusion}
We have discussed feedforward neural networks, a biologically inspired computing model that dominates modern machine learning. Feedforward neural networks are complicated networks of simple units which are arranged in a layered architecture. By propagating an input through its layers, a neural network can make sophisticated predictions, such as the class that the input is most likely to belong to.

Neural networks can be represented as a chain of matrix operations and applications of nonlinear functions. The parameters of the model are chosen during training, where a cost function that measures the performance of the network is minimized. The most common algorithm to achieve this is stochastic gradient descent, which requires the computation of the gradient of the cost function. This is efficiently handled by the back-propagation algorithm.

Deep learning, the branch of machine learning that is concerned with the development of deep neural networks, has enabled an outstanding number of advances in the field in the last 10 years. We believe that, with ever-increasing datasets and computational power, as well as the development of more complex and refined models, neural networks will continue to have a great impact on technology in the future and will power more and more intelligent systems that further improve the quality of life.